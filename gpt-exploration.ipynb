{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Function to generate embeddings using BERT\n",
    "def get_bert_embeddings(model, tokenizer, sentence):\n",
    "    # Tokenize the sentence and convert to tensor\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    # Generate outputs using BERT\n",
    "    outputs = model(**inputs)\n",
    "    # Extract the embeddings from the last hidden state\n",
    "    embeddings = outputs.last_hidden_state\n",
    "    return embeddings, inputs\n",
    "\n",
    "# Function to compute cosine similarity\n",
    "def cosine_similarity(embedding1, embedding2):\n",
    "    return F.cosine_similarity(embedding1, embedding2, dim=0)\n",
    "\n",
    "# Initialize BERT base model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Sentences with multiple meanings of the word 'flies'\n",
    "sentence1 = \"Time flies like an arrow.\"\n",
    "sentence2 = \"Fruit flies like a banana.\"\n",
    "\n",
    "# Generate embeddings and tokenized inputs\n",
    "embeddings1, inputs1 = get_bert_embeddings(model, tokenizer, sentence1)\n",
    "embeddings2, inputs2 = get_bert_embeddings(model, tokenizer, sentence2)\n",
    "\n",
    "# Find the position of the word 'flies' in both sentences\n",
    "word = 'flies'\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(word))\n",
    "positions1 = [i for i, token_id in enumerate(inputs1['input_ids'][0]) if token_id in token_ids]\n",
    "positions2 = [i for i, token_id in enumerate(inputs2['input_ids'][0]) if token_id in token_ids]\n",
    "\n",
    "# Extract embeddings for the word 'flies' from both sentences\n",
    "embedding1_flies = embeddings1[0, positions1[0], :]\n",
    "embedding2_flies = embeddings2[0, positions2[0], :]\n",
    "\n",
    "# Compute cosine similarity\n",
    "similarity = cosine_similarity(embedding1_flies, embedding2_flies)\n",
    "\n",
    "print(similarity)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
